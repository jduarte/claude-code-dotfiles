[
  {
    "acronym": "crawled-product-data-service",
    "name": "Crawled Product Data Service",
    "description": "A product cache and crawl scheduler that provides a JSON API to expose product information crawled from retailer websites such as Amazon and Walmart. Integrates with cpds-importio-service and crawler-scheduler-service to schedule product URLs to be crawled by Import.io and/or the Salsify crawler.",
    "category": "GitHub Repos",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "CPDS",
    "name": "Crawled Product Data Service",
    "description": "Acronym for Crawled Product Data Service. A product cache and crawl scheduler that stores and serves product data crawled from retailer websites. Determines the appropriate data vendor based on retailer and usage, sends ProductScheduleEvents via Kafka to crawl services, and caches the crawled product data for client requests.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "cpds-importio-service",
    "name": "CPDS Import.io Service",
    "description": "A service that integrates with CPDS (Crawled Product Data Service) to handle crawling operations through the Import.io data vendor. Receives ProductScheduleEvents from CPDS and coordinates with Import.io to extract product data from retailer websites.",
    "category": "GitHub Repos",
    "links": [
      {
        "url": "https://github.com/salsify/cpds-importio-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "crawler-scheduler-service",
    "name": "Crawler Scheduler Service",
    "description": "A service that integrates with CPDS (Crawled Product Data Service) to handle crawling operations through the Salsify crawler. Receives ProductScheduleEvents from CPDS and schedules URLs to be crawled by the internal Salsify crawler.",
    "category": "GitHub Repos",
    "links": [
      {
        "url": "https://github.com/salsify/crawler-scheduler-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "CPDS Cache",
    "name": "CPDS Cache",
    "description": "The caching layer within the Crawled Product Data Service that stores product data organized by vendor (based on retailer and usage). Supports Cache-Control max-age headers to prevent returning stale data. The cache can be configured to skip specific retailers during issues via the RETAILERS_TO_SKIP_FROM_CACHE environment variable.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "ProductScheduleEvent",
    "name": "Product Schedule Event",
    "description": "A Kafka event sent by CPDS when a product URL needs to be crawled. Sent to the appropriate crawl service (cpds-importio-service or crawler-scheduler-service) based on the determined data vendor for the retailer and usage.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service/blob/master/app/events/product_schedule_event.rb",
        "description": "Source Code"
      }
    ]
  },
  {
    "acronym": "CrawledProductEventBatchHandler",
    "name": "Crawled Product Event Batch Handler",
    "description": "A Kafka consumer in CPDS that listens for product data events from crawl services. When product data has been crawled and extracted, this handler receives the events and writes the data to the CPDS cache.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service/blob/master/app/handlers/crawled_product_event_batch_handler.rb",
        "description": "Source Code"
      }
    ]
  },
  {
    "acronym": "Data Vendor",
    "name": "Data Vendor",
    "description": "In the context of CPDS, a third-party or internal service that provides crawled product data. Examples include Import.io (external vendor) and the Salsify Crawler (internal). CPDS determines the appropriate vendor based on the retailer and usage parameters.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "GitHub Repository"
      }
    ]
  },
  {
    "acronym": "Insights Data Pipeline",
    "name": "Insights Data Pipeline",
    "description": "The data pipeline architecture that powers Salsify Insights reporting. CPDS is a component of this pipeline, providing cached product data that reporting engines use to generate reports about product information from retailer websites.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://salsify.atlassian.net/wiki/spaces/ALYS/pages/2393769238/Insights+Data+Pipeline",
        "description": "Confluence Wiki"
      }
    ]
  },
  {
    "acronym": "Salsify Crawler",
    "name": "Salsify Crawler",
    "description": "An internal Salsify web crawler used to extract product data from retailer websites. Works alongside Import.io as a data vendor option for CPDS. Currently crawls Amazon US with plans to expand to additional retailers.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "CPDS GitHub Repository"
      },
      {
        "url": "https://github.com/salsify/crawler-scheduler-service",
        "description": "Crawler Scheduler Service"
      }
    ]
  },
  {
    "acronym": "Import.io",
    "name": "Import.io",
    "description": "An external data vendor service used by Salsify for web crawling and product data extraction from retailer websites. CPDS integrates with Import.io through the cpds-importio-service to schedule and retrieve crawled product data.",
    "category": "Partners",
    "links": [
      {
        "url": "https://github.com/salsify/cpds-importio-service",
        "description": "CPDS Import.io Service"
      }
    ]
  },
  {
    "acronym": "Cache Validator",
    "name": "Cache Validator",
    "description": "A tool in CPDS used to compare cached product data between different data vendors (Import.io vs Salsify Crawler). Generates an Excel document with parity scores to identify differences and ensure data consistency before rolling out org reports.",
    "category": "Engineering",
    "links": [
      {
        "url": "https://github.com/salsify/crawled-product-data-service",
        "description": "GitHub Repository"
      }
    ]
  }
]
